{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# FedML usage example in IBM Watsonx.ai "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os, types\n",
                "import pandas as pd\n",
                "from botocore.client import Config\n",
                "import ibm_boto3"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Pre-req steps required in IBM Watsonx.ai to load the needed config files from workspace Data Assets"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "In order to import config files from the workspace, you will need to use the code snippet tool to add the credentials of your S3 bucket to the notebook. The credentials remain the same between the assets loaded in, \n",
                "but the `'FILE'` parameter changes to the name of the asset you are trying to use.\n",
                "\n",
                "These cells that contain the credentials should be marked with the following:\n",
                "\n",
                "```\n",
                "# @hidden_cell\n",
                "# The following code contains metadata for a file in your project storage.\n",
                "# You might want to remove secret properties before you share your notebook.\n",
                "```\n",
                "\n",
                "This will provide the option to keep the sensitive cells hidden upon sharing the link to the notebook instance. Note, by default the inserted code labels the dict as `storage_metadata`."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "For more information on how to get the credentials, please refer to these [IBM Waston Studio docs](https://www.ibm.com/docs/en/cloud-paks/cp-data/4.8.x?topic=scripts-loading-accessing-data-in-notebook). When inserting the code to cell in the notebook instance, you will want to select `load as credentials`. Ensure you load this code snippet to a fresh cell."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# @hidden_cell\n",
                "# The following code contains metadata for a file in your project storage.\n",
                "# You might want to remove secret properties before you share your notebook.\n",
                "\n",
                "dsp_config_json = {\n",
                "    'IAM_SERVICE_ID': <service_id>,\n",
                "    'IBM_API_KEY_ID': <key_id>,\n",
                "    'ENDPOINT': <s3_endpoint>,\n",
                "    'IBM_AUTH_ENDPOINT': <auth_endpoint>,\n",
                "    'BUCKET': <bucket_name>,\n",
                "    'FILE': <file_name>\n",
                "}"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "The cell below only needs to be run with the first credentials, as the `'FILE'` parameter (which is the only one changing on each asset) is not used."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "client = ibm_boto3.client(service_name='s3',\n",
                "    ibm_api_key_id=dsp_config_json['IBM_API_KEY_ID'],\n",
                "    ibm_service_instance_id=dsp_config_json['IAM_SERVICE_ID'],\n",
                "    ibm_auth_endpoint=dsp_config_json['IBM_AUTH_ENDPOINT'],\n",
                "    config=Config(signature_version='oauth'),\n",
                "    endpoint_url=dsp_config_json['ENDPOINT'])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "client.download_file(Bucket=dsp_config_json['BUCKET'], Key=dsp_config_json['FILE'], Filename=dsp_config_json['FILE'])"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Note the variable name change below from `dsp_config_json` to `aic_config`. We advise to do the same for each new JSON asset that is imported into the notebook."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# @hidden_cell\n",
                "# The following code contains metadata for a file in your project storage.\n",
                "# You might want to remove secret properties before you share your notebook.\n",
                "\n",
                "aic_config = {\n",
                "    'IAM_SERVICE_ID': <service_id>,\n",
                "    'IBM_API_KEY_ID': <key_id>,\n",
                "    'ENDPOINT': <s3_endpoint>,\n",
                "    'IBM_AUTH_ENDPOINT': <auth_endpoint>,\n",
                "    'BUCKET': <bucket_name>,\n",
                "    'FILE': <file_name>\n",
                "}"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "client.download_file(Bucket=aic_config['BUCKET'], Key=aic_config['FILE'], Filename=aic_config['FILE'])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# @hidden_cell\n",
                "# The following code contains metadata for a file in your project storage.\n",
                "# You might want to remove secret properties before you share your notebook.\n",
                "\n",
                "docker_registry = {\n",
                "    'IAM_SERVICE_ID': <service_id>,\n",
                "    'IBM_API_KEY_ID': <key_id>,\n",
                "    'ENDPOINT': <s3_endpoint>,\n",
                "    'IBM_AUTH_ENDPOINT': <auth_endpoint>,\n",
                "    'BUCKET': <bucket_name>,\n",
                "    'FILE': <file_name>\n",
                "}"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "client.download_file(Bucket=docker_registry['BUCKET'], Key=docker_registry['FILE'], Filename=docker_registry['FILE'])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# @hidden_cell\n",
                "# The following code contains metadata for a file in your project storage.\n",
                "# You might want to remove secret properties before you share your notebook.\n",
                "\n",
                "github_info = {\n",
                "    'IAM_SERVICE_ID': <service_id>,\n",
                "    'IBM_API_KEY_ID': <key_id>,\n",
                "    'ENDPOINT': <s3_endpoint>,\n",
                "    'IBM_AUTH_ENDPOINT': <auth_endpoint>,\n",
                "    'BUCKET': <bucket_name>,\n",
                "    'FILE': <file_name>\n",
                "}"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "client.download_file(Bucket=github_info['BUCKET'], Key=github_info['FILE'], Filename=github_info['FILE'])"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Pip install  FedML "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "pip install fedml-dsp"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Import FedML"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import fedml_dsp\n",
                "from fedml_dsp import DbConnection"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import seaborn as sns"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Connect to SAP Datasphere "
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "The string below should be whatever your dsp configuration JSON file is called. You can run an `ls` after loading in the files from above to verify what you have labeled it."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "db = DbConnection(url=\"./config.json\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Data discovery & exploration (of Quality SAP semantic data )  with single line of code."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "db.get_schema_views()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Read data from SAP Datasphere semantic models "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "data = db.get_data_with_headers(\"IRIS_VIEW\")\n",
                "iris_df = pd.DataFrame(data[0], columns=data[1])\n",
                "iris_df.head()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Example usage of Reading data directly into PySpark DataFrame. "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "query = \"select * from \\\"SCE\\\".\\\"IRIS_VIEW\\\" limit 5\"\n",
                "db.execute_query_pyspark(query)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Continue with regular ML flow tasks; eg; Scikit-Learn linear regression model training"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import numpy as np\n",
                "from sklearn.linear_model import LinearRegression\n",
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn.metrics import mean_absolute_error, mean_squared_error"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "iris_clean_df = iris_df.dropna()\n",
                "iris_clean_df.drop(\"species\", axis=1, inplace=True)\n",
                "iris_clean_df.head()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "label_col = \"petal_length\"\n",
                "y = iris_clean_df[label_col]\n",
                "iris_clean_df.drop(label_col, axis=1, inplace=True)\n",
                "print(np.shape(iris_clean_df), np.shape(y))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "X_train, X_test, y_train, y_test = train_test_split(iris_clean_df, y, test_size=0.3)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "lr = LinearRegression()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "lr.fit(X_train, y_train)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "predictions = lr.predict(X_test)\n",
                "predictions"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print('Mean Absolute Error:', mean_absolute_error(y_test, predictions))\n",
                "print('Mean Squared Error:', mean_squared_error(y_test, predictions))\n",
                "print('Mean Root Squared Error:', np.sqrt(mean_squared_error(y_test, predictions)))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Example: SAP AI Core Deployment "
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "For more information on AI Core functions, please refer to our [AI Core function docs](https://github.wdf.sap.corp/SCE/FedML-Generic/blob/main/fedml-dsp.md)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "APPLICATION_NAME = \"watson-x-testing1\""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from fedml_dsp import Fedml "
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Loading in AI Core credentials:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "try:\n",
                "    fedml = Fedml(aic_service_key='aic_service_key.json')\n",
                "except:\n",
                "    raise Exception(\"Fedml constructor failed.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Onboarding AI Core resources:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "try:\n",
                "    fedml.onboard_ai_core(\n",
                "                        create_resource_group=False, # set this to True if the GitHub repo is not already onboarded\n",
                "                        resource_group='default',\n",
                "                        onboard_new_repo=True,\n",
                "                        github_info_path=\"./github_info.json\",\n",
                "                        secret_path=\"./docker_registry.json\"\n",
                "                    )\n",
                "except:\n",
                "    raise Exception(\"AI Core resource onboarding failed.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Registering the application:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "try:\n",
                "    application_details = {\n",
                "        \"application_name\": APPLICATION_NAME, \n",
                "        \"revision\": \"HEAD\", \n",
                "        \"repository_url\": <repository_url>,\n",
                "        \"path\": <path_to_yaml_config>\n",
                "    }\n",
                "\n",
                "    fedml.register_application(application_details=application_details)\n",
                "except:\n",
                "    raise Exception(\"Application registration failed.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Deployment to AI Core:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "try:\n",
                "    deployment_config = {\n",
                "        \"name\": APPLICATION_NAME, \n",
                "        \"resource_group\": \"default\", \n",
                "        \"scenario_id\": <scenario_id>,\n",
                "        \"executable_id\": <executable_id>\n",
                "    }\n",
                "\n",
                "    endpoint = fedml.ai_core_deploy(deployment_config=deployment_config)\n",
                "except:\n",
                "    raise Exception(\"Deployment to AI Core failed\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Data formatting and inferencing the endpoint:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def get_test_data():\n",
                "    \"\"\"\n",
                "    Grab test data for inferencing the model.\n",
                "    \"\"\"\n",
                "    org_data = db.get_data_with_headers(table_name=\"BREASTCANCER_VIEW\", size=1)\n",
                "    org_data = pd.DataFrame(org_data[0], columns=org_data[1])\n",
                "    org_data = org_data.sample(frac=1).reset_index(drop=True)\n",
                "    org_data = org_data[500:]\n",
                "    org_data.fillna(0, inplace=True)\n",
                "\n",
                "    y = org_data['diagnosis']\n",
                "    X = org_data.drop(['diagnosis'], axis=1)\n",
                "\n",
                "    return X"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "try:\n",
                "    X = get_test_data()\n",
                "\n",
                "    headers = {\n",
                "        \"Authorization\": fedml.get_ai_core_token(),\n",
                "        \"ai-resource-group\": \"default\",\n",
                "        \"Content-Type\": \"text/csv\"}\n",
                "\n",
                "    temp = X.to_json()\n",
                "    print()\n",
                "    print(X.to_json())\n",
                "    print()\n",
                "\n",
                "    response_data = fedml.ai_core_inference(\n",
                "        endpoint=endpoint,\n",
                "        headers=headers,\n",
                "        body=X.to_json()\n",
                "    )\n",
                "\n",
                "    print()\n",
                "    print(\"Response data:\")\n",
                "    print(response_data)\n",
                "except:\n",
                "    raise Exception(\"Model inferencing failed.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        }
    ],
    "metadata": {},
    "nbformat": 4,
    "nbformat_minor": 1
}