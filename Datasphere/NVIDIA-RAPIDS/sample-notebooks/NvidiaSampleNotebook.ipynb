{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Sample notebook showing end-to-end ML flow using the FedML DSP Library in NVIDIA GPU notebook."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## The FedML DSP Library reads the training data via SAP Datasphere, trains the model, deploys the model in SAP AI Core and the inference result is written back to SAP Datasphere."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Install fedml_dsp library"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "%pip install fedml-dsp"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from fedml_dsp import DbConnection, Fedml\n",
                "import cudf, cuml, cupy\n",
                "import json"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Connect to SAP Datasphere , Explore & Acquire Data"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 1.1 Create DbConnection instance to get data from SAP Datasphere."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "with open('config.json', 'r') as f:\n",
                "    config = json.load(f)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "db = DbConnection()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 1.2 Query the SAP Datasphere data using SQL Queries. Get the data as a CUDF DataFrame"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "%%time\n",
                "data = db.get_data_with_headers_cudf('SMALLCOVTYPE_VIEW', 1)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "type(data)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "data.head(5)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "data.info()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 1.3 Preprocess the data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def preprocess_data(concat_data):\n",
                "    \n",
                "    #map categorical values to numbers\n",
                "    lable = concat_data['cover_type']\n",
                "    \n",
                "    #fix datatypes\n",
                "    df_X = concat_data.drop(['cover_type'], axis=1)\n",
                "    df_X = df_X.astype('float64')\n",
                "    \n",
                "    return df_X, lable"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df_X, lable = preprocess_data(data)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Now, using the data, train the model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "x_train, x_test, y_train, y_test  = cuml.train_test_split(df_X, lable, train_size=0.8)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 2.1 Train the LogisticRegression model using the fit method"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from cuml import LogisticRegression"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "model = LogisticRegression().fit(x_train, y_train)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 2.2 Save the model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import joblib"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# save\n",
                "joblib.dump(model, 'LR_model.pkl')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Deploy the model to SAP AI Core"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "For more detailes of how to deploy a machine learning model to SAP AI Core and YAML file template, please refer to [(here)](https://github.tools.sap/btp-use-case-factory/FedML/blob/main/DSP/fedml-dsp.md).\n",
                "\n",
                "Prerequisites before proceeding with the below cells : You have containerized your model for deployment and hosted the image in a container registry ( dockerhub, ecr etc)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 3.1 Create a AI Core Service Key"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "You can create a AI Core Service Key by following these steps [(here)](https://help.sap.com/docs/sap-ai-core/sap-ai-core-service-guide/create-service-key) and [(here)](https://developers.sap.com/tutorials/ai-core-setup.html)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "fedml = Fedml(aic_service_key='aic_service_key.json')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 3.2 Onboard ai core resources"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "You will need to onboard any ai core resources needed. These include your github repository, AI core resource group, and secret to provide AI core pull premissions to your docker registry."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "fedml.onboard_ai_core(create_resource_group=False,\n",
                "                    resource_group=\"<your resource group>\", \n",
                "                    onboard_new_repo=False,\n",
                "                    github_info_path=\"github_info.json\",\n",
                "                    secret_path=\"secret.json\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 3.3 Register application"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "You need to register the application you want to use in AI Core. You only need to perform this step when you need to register a new application. So if you are using an already existing AI Core application for your deployment, skip this step."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "application_details = {\n",
                "    \"application_name\": \"<your application name>\",\n",
                "    \"revision\":\"HEAD\",\n",
                "    \"repository_url\": \"https://github.com/username/repo_name\", # Change this\n",
                "    \"path\": \"deployment\"}"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "fedml.register_application(application_details=application_details)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 3.4 Deploy to AI Core"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "deployment_config = {\n",
                "    \"name\": \"<application name>\", \n",
                "    \"resource_group\": \"<resource group name>\", \n",
                "    \"scenario_id\": \"<scenario id>\", \n",
                "    \"executable_id\": \"<executable id>\"\n",
                "}"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "endpoint = fedml.ai_core_deploy(deployment_config=deployment_config)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Inference the deployed model by passing the test data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "headers = {\"Authorization\":fedml.get_ai_core_token(),\n",
                "           \"ai-resource-group\": \"<resource group name>\",\n",
                "           \"Content-Type\": \"text/csv\"}"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "response_data = fedml.ai_core_inference(endpoint=endpoint,headers=headers,body=x_test.to_json(orient='records'))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "res = response_data.json"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(res)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Store the inferencing result in SAP Datasphere"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 5.1 Store the inference result in the pandas dataframe"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "dwc_data = x_test.iloc[:,:-1]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "dwc_data = dwc_data.assign(cover_type = res['prediction'])\n",
                "dwc_data"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 5.2 Create a table in Datasphere for storing the inference result"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "db.create_table(\"CREATE TABLE Log_Reg_Model (elevation INTEGER PRIMARY KEY, aspect INTEGER, slope INTEGER,\\\n",
                "    horizontal_distance_to_hydrology INTEGER, vertical_distance_to_hydrology INTEGER, \\\n",
                "    horizontal_distance_to_roadways INTEGER, hillshade_9am INTEGER, hillshade_noon INTEGER, hillshade_3pm INTEGER,\\\n",
                "    horizontal_distance_to_fire_points INTEGER, wilderness_area_1 INTEGER, wilderness_area_2 INTEGER,\\\n",
                "    wilderness_area_3 INTEGER, wilderness_area_4 INTEGER, soil_type_1 bool, soil_type_2 bool, soil_type_3 bool,\\\n",
                "    soil_type_4 bool, soil_type_5 bool, soil_type_6 bool, soil_type_7 bool, soil_type_8 bool, soil_type_9 bool,\\\n",
                "    soil_type_10 bool, soil_type_11 bool, soil_type_12 bool, soil_type_13 bool, soil_type_14 bool, soil_type_15 bool,\\\n",
                "    soil_type_16 bool, soil_type_17 bool, soil_type_18 bool, soil_type_19 bool, soil_type_20 bool, soil_type_21 bool,\\\n",
                "    soil_type_22 bool, soil_type_23 bool, soil_type_24 bool, soil_type_25 bool, soil_type_26 bool, soil_type_27 bool,\\\n",
                "    soil_type_28 bool, soil_type_29 bool, soil_type_30 bool, soil_type_31 bool, soil_type_32 bool, soil_type_33 bool,\\\n",
                "    soil_type_34 bool, soil_type_35 bool, soil_type_36 bool, soil_type_37 bool, soil_type_38 bool, soil_type_39 bool,\\\n",
                "    soil_type_40 bool, cover_type INTEGER)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "db.insert_into_table('Log_Reg_Model', dwc_data)"
            ]
        }
    ],
    "metadata": {},
    "nbformat": 4,
    "nbformat_minor": 4
}